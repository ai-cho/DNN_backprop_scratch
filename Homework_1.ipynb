{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FvNNosSgFm08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__ #check version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HngDwQyUF7qI",
        "outputId": "06eee14e-758b-4637-9e8b-ad0512f2e912"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.25.2', '2.2.1+cu121')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byYyI34mGikO",
        "outputId": "171e0840-5269-49ec-ce91-2d6b58f09776"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bad90209a30>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task1 (np vs torch)"
      ],
      "metadata": {
        "id": "JrMFUdqAF4CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task1 using Numpy\n",
        "x1_n = np.array([1.0, 2.0, 3.0])\n",
        "x2_n = np.array([4.0, 5.0, 6.0])\n",
        "\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "def ReLU(x): # define ReLU using numpy # x.shape (4,)\n",
        "  return np.maximum(x, 0)\n",
        "\n",
        "def Softmax(x): # define Softmax using numpy # x.shape (2,)\n",
        "  return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "\n",
        "def NN_np(input, dropout = False, p = 0, random_seed = 42): # define neural network\n",
        "  hidden_nodes = np.dot(input, w1_n) # shape (4,)\n",
        "  hidden_nodes_act = ReLU(hidden_nodes) # apply activatin function ReLU\n",
        "  if dropout == True:\n",
        "    np.random.seed(random_seed)\n",
        "    drop = np.random.rand(4) # 제거될 확률\n",
        "    drop = drop < p\n",
        "    hidden_nodes_act = hidden_nodes_act * drop\n",
        "    hidden_nodes_act /= (1-p)\n",
        "  output_nodes_np = np.dot(hidden_nodes_act, w2_n) # shape (2,)\n",
        "  output_nodes_act = Softmax(output_nodes_np) # apply activation function Softmax\n",
        "  return hidden_nodes, hidden_nodes_act, output_nodes_np, output_nodes_act\n",
        "\n",
        "print('when input is x1: ', np.round(NN_np(x1_n)[3], 4))\n",
        "print('when input is x2: ', np.round(NN_np(x2_n)[3], 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe55OVqFVwY8",
        "outputId": "3a93cfa8-5d51-47e9-92ad-311fe4f2ae2f"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:  [0.1324 0.8676]\n",
            "when input is x2:  [0.0145 0.9855]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task1 using Pytorch\n",
        "x1_t = torch.tensor([1.0, 2.0, 3.0])\n",
        "x2_t = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(3, 4, bias = False)\n",
        "    self.linear1.weight.data = w1_t.T\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.linear2 = nn.Linear(4, 2, bias = False)\n",
        "    self.linear2.weight.data = w2_t.T\n",
        "    self.act2 = nn.Softmax(dim = -1)\n",
        "\n",
        "  def forward(self, x, dropout = False):\n",
        "    x = self.linear1(x)\n",
        "    x = self.act1(x)\n",
        "    if dropout == True:\n",
        "      x = self.dropout(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.act2(x)\n",
        "    return x\n",
        "\n",
        "NN_torch = NN()\n",
        "print('when input is x1: ', NN_torch(x1_t))\n",
        "print('when input is x2: ', NN_torch(x2_t))"
      ],
      "metadata": {
        "id": "36sZzNQNGpKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892942dd-f124-477d-b506-3f7d6fa3a322"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:  tensor([0.1324, 0.8676], grad_fn=<SoftmaxBackward0>)\n",
            "when input is x2:  tensor([0.0145, 0.9855], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task2 (np vs torch) - w1 gradient without updates"
      ],
      "metadata": {
        "id": "vbXY3YvHF9Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task2 using Numpy\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "y1_n = np.array([0, 1])\n",
        "y2_n = np.array([1, 0])\n",
        "def CEE_np(y_pred, y_target):\n",
        "  y_pred = Softmax(y_pred)\n",
        "  return -np.sum(y_target*np.log(y_pred))\n",
        "\n",
        "def gradient_w1(input, target, i, j, dropout = False, p = 0, random_seed = 42): # i_1: start, j_1: end\n",
        "  if dropout == True:\n",
        "    output = NN_np(input, True, p, random_seed = 42)[-1]\n",
        "  else:\n",
        "    output = NN_np(input)[-1]\n",
        "  dL_do = Softmax(output) - target # error\n",
        "  do_dy = np.zeros((2,2))\n",
        "  for i_1 in range(2):\n",
        "    for j_1 in range(2):\n",
        "      if i_1 == j_1:\n",
        "        do_dy[i_1][j_1] = output[0]*output[1]\n",
        "      else:\n",
        "        do_dy[i_1][j_1] = -output[0]*output[1]\n",
        "  dy_dr_j = w2_n[j].T\n",
        "  dr_j_dh = np.array([1 if NN_np(input)[0][j] > 0 else 0])\n",
        "  dh_dw_ij = input[i]\n",
        "  result = np.dot(dL_do, do_dy)\n",
        "  result = np.dot(result, dy_dr_j)\n",
        "  result = np.dot(result, dr_j_dh)\n",
        "  result = np.dot(result, dh_dw_ij)\n",
        "  return round(result.item(), 4)\n",
        "\n",
        "def get_weight1_grad_np(input, target, dropout = False, p = 0, random_seed = 42):\n",
        "  weight_grad = np.zeros((3,4))\n",
        "  for start in range(3):\n",
        "    for end in range(4):\n",
        "      if dropout == True:\n",
        "        weight_grad[start][end] = gradient_w1(input, target, start, end, dropout, p, random_seed = 42)\n",
        "        idx = np.where(NN_np(input, True, p, random_seed)[1] == 0)[0] # 00인 지점은 가중치 0으로 세팅\n",
        "        for i in idx:\n",
        "          weight_grad[:, i] = 0.0\n",
        "      else:\n",
        "        weight_grad[start][end] = gradient_w1(input, target, start, end)\n",
        "\n",
        "  return weight_grad\n",
        "\n",
        "print('when input is x1: \\n', get_weight1_grad_np(x1_n, y1_n))\n",
        "print()\n",
        "print('when input is x2: \\n', get_weight1_grad_np(x2_n, y2_n))"
      ],
      "metadata": {
        "id": "k0ROT6DF305M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4911e0db-8df7-4539-ce0c-fdab013aa2c3"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1: \n",
            " [[-0.0074 -0.0074 -0.0074 -0.0074]\n",
            " [-0.0149 -0.0149 -0.0149 -0.0149]\n",
            " [-0.0223 -0.0223 -0.0223 -0.0223]]\n",
            "\n",
            "when input is x2: \n",
            " [[0.0083 0.0083 0.0083 0.0083]\n",
            " [0.0104 0.0104 0.0104 0.0104]\n",
            " [0.0124 0.0124 0.0124 0.0124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task2 using Pytorch\n",
        "import torch.optim as optim\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "y1_t = torch.tensor([0, 1], dtype = torch.float32)\n",
        "y2_t = torch.tensor([1, 0], dtype = torch.float32)\n",
        "\n",
        "def get_weight_grad_t(input, target):\n",
        "  NN_torch = NN()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  pred = NN_torch(input)\n",
        "  loss = loss_fn(pred, target)\n",
        "  loss.backward()\n",
        "  result = NN_torch.linear1.weight.grad\n",
        "  return result.T\n",
        "\n",
        "print('when input is x1:\\n', get_weight_grad_t(x1_t, y1_t))\n",
        "print()\n",
        "print('when input is x2:\\n', get_weight_grad_t(x2_t, y2_t))"
      ],
      "metadata": {
        "id": "4S9aiT_3JKfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2264ef-c429-4167-cc7a-ddc8756bcba2"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:\n",
            " tensor([[-0.0074, -0.0074, -0.0074, -0.0074],\n",
            "        [-0.0149, -0.0149, -0.0149, -0.0149],\n",
            "        [-0.0223, -0.0223, -0.0223, -0.0223]])\n",
            "\n",
            "when input is x2:\n",
            " tensor([[0.0083, 0.0083, 0.0083, 0.0083],\n",
            "        [0.0104, 0.0104, 0.0104, 0.0104],\n",
            "        [0.0124, 0.0124, 0.0124, 0.0124]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task3 (np vs torch) - updated w1, w2 (100 epoch)"
      ],
      "metadata": {
        "id": "ynzVS5RuGTaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before task3 - w2 gradient using np\n",
        "def gradient_w2(input, target, i, j, dropout = False, p = 0, random_seed = 42): # i_1: start, j_1: end\n",
        "  if dropout == True:\n",
        "    output = NN_np(input, dropout, p, random_seed)[-1]\n",
        "  else:\n",
        "    output = NN_np(input)[-1]\n",
        "  dL_do = Softmax(output) - target\n",
        "  do_dy = np.zeros((2,2))\n",
        "  for i_1 in range(2):\n",
        "    for j_1 in range(2):\n",
        "      if i_1 == j_1:\n",
        "        do_dy[i_1][j_1] = output[0]*output[1]\n",
        "      else:\n",
        "        do_dy[i_1][j_1] = -output[0]*output[1]\n",
        "  dy_dr_j = NN_np(input)[1][i] # 히든 after_act 값만 얻으면 됨. (즉, dropout되든 안되든 일단 곱하고 뒤에서 dropout된 것들의 값은 0으로 초기화시킴.)\n",
        "  result = np.dot(dL_do, do_dy)[j]\n",
        "  result = result * dy_dr_j\n",
        "  return round(result.item(), 4)\n",
        "\n",
        "\n",
        "\n",
        "def get_weight2_grad_np(input, target, dropout = False, p = 0, random_seed = 42):\n",
        "  weight_grad = np.zeros((4,2))\n",
        "  for start in range(4):\n",
        "    for end in range(2):\n",
        "      if dropout == True:\n",
        "        weight_grad[start][end] = gradient_w2(input, target, start, end, dropout, p, random_seed)\n",
        "        idx = np.where(NN_np(input, True, p, random_seed)[1] == 0)[0] # 00인 지점은 가중치 0으로 세팅 #idx가 고정되는 error 발생\n",
        "        for i in idx:\n",
        "          weight_grad[i, :] = 0.0\n",
        "      else:\n",
        "        weight_grad[start][end] = gradient_w2(input, target, start, end)\n",
        "  return weight_grad"
      ],
      "metadata": {
        "id": "G_cD6rqE_Csh"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using numpy - input x1\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "for i in range(100): # 100 epochs\n",
        "  random_seed = i+40\n",
        "  w1_grad = get_weight1_grad_np(x1_n, y1_n, True, 0.4, random_seed)\n",
        "  w2_grad = get_weight2_grad_np(x1_n, y1_n, True, 0.4, random_seed)\n",
        "  w1_n -= 0.01*w1_grad\n",
        "  w2_n -= 0.01*w2_grad\n",
        "print('input: x1')\n",
        "print()\n",
        "print('w1: ', np.round(w1_n, 4))\n",
        "print()\n",
        "print('w2: ', np.round(w2_n, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2eVNOOTPxuh",
        "outputId": "1319fbb6-92cd-40f8-f554-1764037c28c3"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x1\n",
            "\n",
            "w1:  [[0.1107 0.2103 0.3085 0.4107]\n",
            " [0.5214 0.6207 0.7169 0.8213]\n",
            " [0.9322 1.031  1.1254 1.232 ]]\n",
            "\n",
            "w2:  [[0.1191 0.3809]\n",
            " [0.3274 0.5726]\n",
            " [0.5234 0.7766]\n",
            " [0.7254 0.9746]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using numpy - input x2\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "for i in range(100): # 100 epochs\n",
        "  random_seed = i+40\n",
        "  w1_grad = get_weight1_grad_np(x2_n, y2_n, True, 0.4, random_seed)\n",
        "  w2_grad = get_weight2_grad_np(x2_n, y2_n, True, 0.4, random_seed)\n",
        "  w1_n -= 0.01*w1_grad\n",
        "  w2_n -= 0.01*w2_grad\n",
        "print('input: x2')\n",
        "print()\n",
        "print('w1: ', np.round(w1_n, 4))\n",
        "print()\n",
        "print('w2: ', np.round(w2_n, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLHDzewAHUq3",
        "outputId": "bf73fa21-2cef-4e49-8bb0-aaa4e0b713f5"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x2\n",
            "\n",
            "w1:  [[0.1104 0.2102 0.3097 0.4128]\n",
            " [0.513  0.6127 0.7122 0.8161]\n",
            " [0.9156 1.0152 1.1146 1.2193]]\n",
            "\n",
            "w2:  [[0.3463 0.1537]\n",
            " [0.5362 0.3638]\n",
            " [0.7412 0.5588]\n",
            " [0.9364 0.7636]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using Pytorch - input x1\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "NN_torch1 = NN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(NN_torch1.parameters(), lr = 0.01)\n",
        "\n",
        "# input: x1\n",
        "for epoch in range(100):\n",
        "  pred = NN_torch1(x1_t, True)\n",
        "  loss = loss_fn(pred, y1_t)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print('input: x1\\n')\n",
        "print('w1: ', NN_torch1.linear1.weight.T)\n",
        "print('w2: ', NN_torch1.linear2.weight.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HRaguo7gDqH",
        "outputId": "659e8a0f-bff1-4bc1-e7c5-413d87dde79f"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x1\n",
            "\n",
            "w1:  tensor([[0.1038, 0.2022, 0.3031, 0.4022],\n",
            "        [0.5076, 0.6045, 0.7062, 0.8043],\n",
            "        [0.9114, 1.0067, 1.1093, 1.2065]], grad_fn=<PermuteBackward0>)\n",
            "w2:  tensor([[0.1184, 0.3816],\n",
            "        [0.3374, 0.5626],\n",
            "        [0.5136, 0.7864],\n",
            "        [0.7277, 0.9723]], grad_fn=<PermuteBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using Pytorch - input x2\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "NN_torch1 = NN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(NN_torch1.parameters(), lr = 0.01)\n",
        "\n",
        "# input: x2\n",
        "for epoch in range(100):\n",
        "  pred = NN_torch1(x2_t, True)\n",
        "  loss = loss_fn(pred, y2_t)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print('input: x2\\n')\n",
        "print('w1: ', NN_torch1.linear1.weight.T)\n",
        "print('w2: ', NN_torch1.linear2.weight.T)"
      ],
      "metadata": {
        "id": "AWOFu2kK1JzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6938e0f8-7f56-405e-e7b1-464f9fcbedbd"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x2\n",
            "\n",
            "w1:  tensor([[0.1032, 0.2008, 0.3007, 0.4000],\n",
            "        [0.5040, 0.6010, 0.7009, 0.8000],\n",
            "        [0.9048, 1.0012, 1.1011, 1.2000]], grad_fn=<PermuteBackward0>)\n",
            "w2:  tensor([[0.3584, 0.1416],\n",
            "        [0.5356, 0.3644],\n",
            "        [0.7389, 0.5611],\n",
            "        [0.9234, 0.7766]], grad_fn=<PermuteBackward0>)\n"
          ]
        }
      ]
    }
  ]
}