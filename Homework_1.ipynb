{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FvNNosSgFm08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__ #check version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HngDwQyUF7qI",
        "outputId": "6c3b13ec-f4ee-44da-f99a-bade0d635c14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.25.2', '2.2.1+cu121')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byYyI34mGikO",
        "outputId": "98edb004-f1ee-4e89-a5ce-0f7ec99fd501"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7954bc3b5a10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task1 (np vs torch)"
      ],
      "metadata": {
        "id": "JrMFUdqAF4CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task1 using Numpy\n",
        "x1_n = np.array([1.0, 2.0, 3.0])\n",
        "x2_n = np.array([4.0, 5.0, 6.0])\n",
        "\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "def ReLU(x): # define ReLU using numpy # x.shape (4,)\n",
        "  return np.maximum(x, 0)\n",
        "\n",
        "def Softmax(x): # define Softmax using numpy # x.shape (2,)\n",
        "  return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "\n",
        "def NN_np(input, dropout = False, p = 0, random_seed = 42): # define neural network\n",
        "  hidden_nodes = np.dot(input, w1_n) # shape (4,)\n",
        "  hidden_nodes_act = ReLU(hidden_nodes) # apply activatin function ReLU\n",
        "  if dropout == True:\n",
        "    np.random.seed(random_seed)\n",
        "    drop = np.random.rand(4) # 제거될 확률\n",
        "    drop = drop < p\n",
        "    hidden_nodes_act = hidden_nodes_act * drop\n",
        "    hidden_nodes_act /= (1-p)\n",
        "  output_nodes_np = np.dot(hidden_nodes_act, w2_n) # shape (2,)\n",
        "  output_nodes_act = Softmax(output_nodes_np) # apply activation function Softmax\n",
        "  return hidden_nodes, hidden_nodes_act, output_nodes_np, output_nodes_act\n",
        "\n",
        "print('when input is x1: ', np.round(NN_np(x1_n)[3], 4))\n",
        "print('when input is x2: ', np.round(NN_np(x2_n)[3], 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe55OVqFVwY8",
        "outputId": "9fec1691-4963-47ba-b1f7-16d9849afba6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:  [0.1324 0.8676]\n",
            "when input is x2:  [0.0145 0.9855]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task1 using Pytorch\n",
        "x1_t = torch.tensor([1.0, 2.0, 3.0])\n",
        "x2_t = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(3, 4, bias = False)\n",
        "    self.linear1.weight.data = w1_t.T\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.linear2 = nn.Linear(4, 2, bias = False)\n",
        "    self.linear2.weight.data = w2_t.T\n",
        "    self.act2 = nn.Softmax(dim = -1)\n",
        "\n",
        "  def forward(self, x, dropout = False):\n",
        "    x = self.linear1(x)\n",
        "    x = self.act1(x)\n",
        "    if dropout == True:\n",
        "      x = self.dropout(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.act2(x)\n",
        "    return x\n",
        "\n",
        "NN_torch = NN()\n",
        "print('when input is x1: ', NN_torch(x1_t))\n",
        "print('when input is x2: ', NN_torch(x2_t))"
      ],
      "metadata": {
        "id": "36sZzNQNGpKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5f165b-c4e6-40ef-b9da-9a13d9c481f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:  tensor([0.1324, 0.8676], grad_fn=<SoftmaxBackward0>)\n",
            "when input is x2:  tensor([0.0145, 0.9855], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task2 (np vs torch) - w1 gradient without updates"
      ],
      "metadata": {
        "id": "vbXY3YvHF9Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task2 using Numpy\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "y1_n = np.array([0, 1])\n",
        "y2_n = np.array([1, 0])\n",
        "def CEE_np(y_pred, y_target):\n",
        "  y_pred = Softmax(y_pred)\n",
        "  return -np.sum(y_target*np.log(y_pred))\n",
        "\n",
        "def gradient_w1(input, target, i, j, dropout = False, p = 0, random_seed = 42): # i_1: start, j_1: end\n",
        "  if dropout == True:\n",
        "    output = NN_np(input, True, p, random_seed)[-1]\n",
        "  else:\n",
        "    output = NN_np(input)[-1]\n",
        "  dL_do = Softmax(output) - target\n",
        "  do_dy = np.zeros((2,2))\n",
        "  for i_1 in range(2):\n",
        "    for j_1 in range(2):\n",
        "      if i_1 == j_1:\n",
        "        do_dy[i_1][j_1] = output[0]*output[1]\n",
        "      else:\n",
        "        do_dy[i_1][j_1] = -output[0]*output[1]\n",
        "  dy_dr_j = w2_n[j].T\n",
        "  dr_j_dh = np.array([1 if NN_np(input)[0][j] > 0 else 0])\n",
        "  dh_dw_ij = input[i]\n",
        "  result = np.dot(dL_do, do_dy)\n",
        "  result = np.dot(result, dy_dr_j)\n",
        "  result = np.dot(result, dr_j_dh)\n",
        "  result = np.dot(result, dh_dw_ij)\n",
        "  return round(result.item(), 4)\n",
        "\n",
        "def get_weight1_grad_np(input, target, dropout = False, p = 0, random_seed = 42):\n",
        "  weight_grad = np.zeros((3,4))\n",
        "  for start in range(3):\n",
        "    for end in range(4):\n",
        "      if dropout == True:\n",
        "        weight_grad[start][end] = gradient_w1(input, target, start, end, dropout, p, random_seed = 42)\n",
        "        idx = np.where(NN_np(input, True, p, random_seed)[1] == 0)[0]\n",
        "        for i in idx:\n",
        "          weight_grad[:, i] = 0.0\n",
        "      else:\n",
        "        weight_grad[start][end] = gradient_w1(input, target, start, end)\n",
        "\n",
        "  return weight_grad\n",
        "\n",
        "print('when input is x1: \\n', get_weight1_grad_np(x1_n, y1_n))\n",
        "print()\n",
        "print('when input is x2: \\n', get_weight1_grad_np(x2_n, y2_n))"
      ],
      "metadata": {
        "id": "k0ROT6DF305M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d36d60-98ae-48e9-d5d8-312ef63d924c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1: \n",
            " [[-0.0074 -0.0074 -0.0074 -0.0074]\n",
            " [-0.0149 -0.0149 -0.0149 -0.0149]\n",
            " [-0.0223 -0.0223 -0.0223 -0.0223]]\n",
            "\n",
            "when input is x2: \n",
            " [[0.0083 0.0083 0.0083 0.0083]\n",
            " [0.0104 0.0104 0.0104 0.0104]\n",
            " [0.0124 0.0124 0.0124 0.0124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task2 using Pytorch\n",
        "import torch.optim as optim\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "y1_t = torch.tensor([0, 1], dtype = torch.float32)\n",
        "y2_t = torch.tensor([1, 0], dtype = torch.float32)\n",
        "\n",
        "def get_weight_grad_t(input, target):\n",
        "  NN_torch = NN()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  pred = NN_torch(input)\n",
        "  loss = loss_fn(pred, target)\n",
        "  loss.backward()\n",
        "  result = NN_torch.linear1.weight.grad\n",
        "  return result.T\n",
        "\n",
        "print('when input is x1:\\n', get_weight_grad_t(x1_t, y1_t))\n",
        "print()\n",
        "print('when input is x2:\\n', get_weight_grad_t(x2_t, y2_t))"
      ],
      "metadata": {
        "id": "4S9aiT_3JKfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bd481d-66c3-4a73-b7b2-6a4a30ddc083"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is x1:\n",
            " tensor([[-0.0074, -0.0074, -0.0074, -0.0074],\n",
            "        [-0.0149, -0.0149, -0.0149, -0.0149],\n",
            "        [-0.0223, -0.0223, -0.0223, -0.0223]])\n",
            "\n",
            "when input is x2:\n",
            " tensor([[0.0083, 0.0083, 0.0083, 0.0083],\n",
            "        [0.0104, 0.0104, 0.0104, 0.0104],\n",
            "        [0.0124, 0.0124, 0.0124, 0.0124]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task3 (np vs torch) - updated w1, w2 (100 epoch)"
      ],
      "metadata": {
        "id": "ynzVS5RuGTaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before task3 - w2 gradient using np\n",
        "def gradient_w2(input, target, i, j, dropout = False, p = 0, random_seed = 42): # i_1: start, j_1: end\n",
        "  if dropout == True:\n",
        "    output = NN_np(input, dropout, p, random_seed)[-1]\n",
        "  else:\n",
        "    output = NN_np(input)[-1]\n",
        "  dL_do = Softmax(output) - target\n",
        "  do_dy = np.zeros((2,2))\n",
        "  for i_1 in range(2):\n",
        "    for j_1 in range(2):\n",
        "      if i_1 == j_1:\n",
        "        do_dy[i_1][j_1] = output[0]*output[1]\n",
        "      else:\n",
        "        do_dy[i_1][j_1] = -output[0]*output[1]\n",
        "  dy_dw_j = NN_np(input)[1][i] # hidden after_act 값만 얻으면 됨. (즉, dropout되든 안되든 일단 곱하고 뒤에서 dropout된 것들의 값은 0으로 초기화시킴.)\n",
        "  result = np.dot(dL_do, do_dy)[j]\n",
        "  result = result * dy_dw_j\n",
        "  return round(result.item(), 4)\n",
        "\n",
        "\n",
        "\n",
        "def get_weight2_grad_np(input, target, dropout = False, p = 0, random_seed = 42):\n",
        "  weight_grad = np.zeros((4,2))\n",
        "  for start in range(4):\n",
        "    for end in range(2):\n",
        "      if dropout == True:\n",
        "        weight_grad[start][end] = gradient_w2(input, target, start, end, dropout, p, random_seed)\n",
        "        idx = np.where(NN_np(input, True, p, random_seed)[1] == 0)[0]\n",
        "        for i in idx:\n",
        "          weight_grad[i, :] = 0.0\n",
        "      else:\n",
        "        weight_grad[start][end] = gradient_w2(input, target, start, end)\n",
        "  return weight_grad"
      ],
      "metadata": {
        "id": "G_cD6rqE_Csh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using numpy - input x1\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "for i in range(100): # 100 epochs\n",
        "  random_seed = i+40\n",
        "  w1_grad = get_weight1_grad_np(x1_n, y1_n, True, 0.4, random_seed)\n",
        "  w2_grad = get_weight2_grad_np(x1_n, y1_n, True, 0.4, random_seed)\n",
        "  w1_n -= 0.01*w1_grad\n",
        "  w2_n -= 0.01*w2_grad\n",
        "print('input: x1')\n",
        "print()\n",
        "print('w1: ', np.round(w1_n, 4))\n",
        "print()\n",
        "print('w2: ', np.round(w2_n, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2eVNOOTPxuh",
        "outputId": "2d0daf61-6a49-47d4-d03d-ec06e2b99064"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x1\n",
            "\n",
            "w1:  [[0.1107 0.2103 0.3085 0.4107]\n",
            " [0.5214 0.6207 0.7169 0.8213]\n",
            " [0.9322 1.031  1.1254 1.232 ]]\n",
            "\n",
            "w2:  [[0.1191 0.3809]\n",
            " [0.3274 0.5726]\n",
            " [0.5234 0.7766]\n",
            " [0.7254 0.9746]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using numpy - input x2\n",
        "w1_n = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7, 0.8],\n",
        "               [0.9, 1.0, 1.1, 1.2]])\n",
        "w2_n = np.array([[0.2, 0.3],\n",
        "                [0.4, 0.5],\n",
        "                [0.6, 0.7],\n",
        "                [0.8, 0.9]])\n",
        "\n",
        "for i in range(100): # 100 epochs\n",
        "  random_seed = i+40\n",
        "  w1_grad = get_weight1_grad_np(x2_n, y2_n, True, 0.4, random_seed)\n",
        "  w2_grad = get_weight2_grad_np(x2_n, y2_n, True, 0.4, random_seed)\n",
        "  w1_n -= 0.01*w1_grad\n",
        "  w2_n -= 0.01*w2_grad\n",
        "print('input: x2')\n",
        "print()\n",
        "print('w1: ', np.round(w1_n, 4))\n",
        "print()\n",
        "print('w2: ', np.round(w2_n, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLHDzewAHUq3",
        "outputId": "740229b5-29c9-42ed-82d7-786d84adb8f0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x2\n",
            "\n",
            "w1:  [[0.1104 0.2102 0.3097 0.4128]\n",
            " [0.513  0.6127 0.7122 0.8161]\n",
            " [0.9156 1.0152 1.1146 1.2193]]\n",
            "\n",
            "w2:  [[0.3463 0.1537]\n",
            " [0.5362 0.3638]\n",
            " [0.7412 0.5588]\n",
            " [0.9364 0.7636]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using Pytorch - input x1\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "NN_torch1 = NN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(NN_torch1.parameters(), lr = 0.01)\n",
        "\n",
        "# input: x1\n",
        "for epoch in range(100):\n",
        "  pred = NN_torch1(x1_t, True)\n",
        "  loss = loss_fn(pred, y1_t)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print('input: x1\\n')\n",
        "print('w1: ', NN_torch1.linear1.weight.T)\n",
        "print('w2: ', NN_torch1.linear2.weight.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HRaguo7gDqH",
        "outputId": "479ba755-7c1b-4eb6-b6f8-803199d2c047"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x1\n",
            "\n",
            "w1:  tensor([[0.1032, 0.2033, 0.3034, 0.4019],\n",
            "        [0.5063, 0.6066, 0.7069, 0.8039],\n",
            "        [0.9095, 1.0099, 1.1103, 1.2058]], grad_fn=<PermuteBackward0>)\n",
            "w2:  tensor([[0.1279, 0.3721],\n",
            "        [0.3180, 0.5820],\n",
            "        [0.5080, 0.7920],\n",
            "        [0.7332, 0.9668]], grad_fn=<PermuteBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task3 using Pytorch - input x2\n",
        "w1_t = torch.tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                   [0.5, 0.6, 0.7, 0.8],\n",
        "                   [0.9, 1.0, 1.1, 1.2]]) # (3, 4)\n",
        "w2_t = torch.tensor([[0.2, 0.3],\n",
        "                   [0.4, 0.5],\n",
        "                   [0.6, 0.7],\n",
        "                   [0.8, 0.9]])  # (4, 2)\n",
        "\n",
        "NN_torch1 = NN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(NN_torch1.parameters(), lr = 0.01)\n",
        "\n",
        "# input: x2\n",
        "for epoch in range(100):\n",
        "  pred = NN_torch1(x2_t, True)\n",
        "  loss = loss_fn(pred, y2_t)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print('input: x2\\n')\n",
        "print('w1: ', NN_torch1.linear1.weight.T)\n",
        "print('w2: ', NN_torch1.linear2.weight.T)"
      ],
      "metadata": {
        "id": "AWOFu2kK1JzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87e259a-28fe-4d97-b0d4-fd5e8b2180e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: x2\n",
            "\n",
            "w1:  tensor([[0.1031, 0.2021, 0.3004, 0.4001],\n",
            "        [0.5039, 0.6027, 0.7004, 0.8002],\n",
            "        [0.9046, 1.0032, 1.1005, 1.2002]], grad_fn=<PermuteBackward0>)\n",
            "w2:  tensor([[0.3592, 0.1408],\n",
            "        [0.5493, 0.3507],\n",
            "        [0.7356, 0.5644],\n",
            "        [0.9324, 0.7676]], grad_fn=<PermuteBackward0>)\n"
          ]
        }
      ]
    }
  ]
}